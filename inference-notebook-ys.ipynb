{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:16:04.599301Z",
     "iopub.status.busy": "2025-11-19T06:16:04.599129Z",
     "iopub.status.idle": "2025-11-19T06:16:04.605322Z",
     "shell.execute_reply": "2025-11-19T06:16:04.604780Z",
     "shell.execute_reply.started": "2025-11-19T06:16:04.599285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/shobdotori/Test\"\n",
    "OUTPUT_DIR = \"./\"\n",
    "OUTPUT_FILE = \"submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:16:04.606971Z",
     "iopub.status.busy": "2025-11-19T06:16:04.606811Z",
     "iopub.status.idle": "2025-11-19T06:17:59.823688Z",
     "shell.execute_reply": "2025-11-19T06:17:59.822764Z",
     "shell.execute_reply.started": "2025-11-19T06:16:04.606958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall numpy==1.26.4 scikit-learn==1.3.2\n",
    "!pip install protobuf==3.20.*\n",
    "!pip install datasets==3.6.0 transformers==4.48.3 torchaudio accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:17:59.825059Z",
     "iopub.status.busy": "2025-11-19T06:17:59.824767Z",
     "iopub.status.idle": "2025-11-19T06:18:22.995158Z",
     "shell.execute_reply": "2025-11-19T06:18:22.994575Z",
     "shell.execute_reply.started": "2025-11-19T06:17:59.825005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm  \n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torchaudio\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:18:22.996381Z",
     "iopub.status.busy": "2025-11-19T06:18:22.995881Z",
     "iopub.status.idle": "2025-11-19T06:18:38.782043Z",
     "shell.execute_reply": "2025-11-19T06:18:38.781266Z",
     "shell.execute_reply.started": "2025-11-19T06:18:22.996350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = 'lucius-40/Whisper-bn-v2'\n",
    "processor = WhisperProcessor.from_pretrained(model_path)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:18:38.783198Z",
     "iopub.status.busy": "2025-11-19T06:18:38.782909Z",
     "iopub.status.idle": "2025-11-19T06:18:38.811923Z",
     "shell.execute_reply": "2025-11-19T06:18:38.811242Z",
     "shell.execute_reply.started": "2025-11-19T06:18:38.783162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading test files...\\n\")\n",
    "\n",
    "test_files = sorted([f for f in os.listdir(DATA_DIR) if f.endswith('.wav')])\n",
    "\n",
    "print(f\"Found {len(test_files)} test files\")\n",
    "\n",
    "if len(test_files) == 0:\n",
    "    print(\"\\nWARNING: No test files found! Check DATA_DIR\")\n",
    "else:\n",
    "    print(f\"\\nTest data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:18:55.854176Z",
     "iopub.status.busy": "2025-11-19T06:18:55.853559Z",
     "iopub.status.idle": "2025-11-19T06:24:34.169194Z",
     "shell.execute_reply": "2025-11-19T06:24:34.168466Z",
     "shell.execute_reply.started": "2025-11-19T06:18:55.854149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Generating test predictions...\\n\")\n",
    "print(f\"Processing {len(test_files)} test files...\\n\")\n",
    "\n",
    "predictions = []\n",
    "errors = []\n",
    "\n",
    "for i, audio_file in enumerate(tqdm(test_files, desc=\"Transcribing\")):\n",
    "    audio_path = os.path.join(DATA_DIR, audio_file)\n",
    "\n",
    "    try:\n",
    "        # Load and resample audio to 16kHz\n",
    "        audio_array, sr = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "        # Extract features\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "\n",
    "        input_features = input_features.to(device)\n",
    "\n",
    "        # Generate transcription\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                language=\"bn\",\n",
    "                task=\"transcribe\",\n",
    "                max_length=225,\n",
    "                num_beams = 4,\n",
    "            )\n",
    "\n",
    "        # Decode prediction\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        predictions.append({\n",
    "            'audio': audio_file,\n",
    "            'text': transcription\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing {audio_file}: {str(e)}\"\n",
    "        errors.append(error_msg)\n",
    "        print(f\"\\n{error_msg}\")\n",
    "\n",
    "        # Add empty prediction\n",
    "        predictions.append({\n",
    "            'audio': audio_file,\n",
    "            'text': \"\"\n",
    "        })\n",
    "\n",
    "print(f\"  Total predictions: {len(predictions)}\")\n",
    "print(f\"  Errors: {len(errors)}\")\n",
    "\n",
    "submission_df = pd.DataFrame(predictions)\n",
    "submission_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Output file ’{OUTPUT_FILE}’ generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:24:48.161827Z",
     "iopub.status.busy": "2025-11-19T06:24:48.161171Z",
     "iopub.status.idle": "2025-11-19T06:24:48.170788Z",
     "shell.execute_reply": "2025-11-19T06:24:48.170069Z",
     "shell.execute_reply.started": "2025-11-19T06:24:48.161804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dfs = pd.read_csv(OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:24:52.236121Z",
     "iopub.status.busy": "2025-11-19T06:24:52.235388Z",
     "iopub.status.idle": "2025-11-19T06:24:52.257388Z",
     "shell.execute_reply": "2025-11-19T06:24:52.256757Z",
     "shell.execute_reply.started": "2025-11-19T06:24:52.236094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dfs"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14372637,
     "sourceId": 119724,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
